{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employee Retention Classification - A Classification Challenge with various Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing General Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing general python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# importing libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# importing libraries for data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# importing libraries for model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# importing libraries for model evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,mean_absolute_percentage_error\n",
    "\n",
    "# importing libraries for model tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# importing tensorflow libraries for deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Our Classification Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains information about employees in a company, including their educational backgrounds, work history, demographics, and employment-related factors. It has been anonymized to protect privacy while still providing valuable insights into the workforce.\n",
    "The source of the dataset is [Kaggle](https://www.kaggle.com/datasets/tawfikelmetwally/employee-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns description:\n",
    "\n",
    "**Target Column:**\n",
    "* **`LeaveorNot`**: a target column (binary).\n",
    "\n",
    "\n",
    "\n",
    "**Numeric Columns:**\n",
    "* **`Age`**: The age of each employee, providing demographic insights (numeric).\n",
    "* **`JoiningYear`**: The year each employee joined the company, indicating their length of service (numeric).\n",
    "* **`ExperienceinCurrentDomain`**: The number of years of experience employees have in their current field (numeric).\n",
    "\n",
    "\n",
    "**Categorical Columns:**\n",
    "* **`PaymentTier`**: Categorization of employees into different salary tiers (3 ordinal categories).\n",
    "* **`Education`**: The educational qualifications of employees, including degree, institution, and field of study (3 ordinal categories).\n",
    "* **`Gender`**: Gender identity of employees, promoting diversity analysis (binary in this dataset).\n",
    "* **`City`**: The location or city where each employee is based or works (3 nominal categories).\n",
    "* **`EverBenched`**: Indicates if an employee has ever been temporarily without assigned work (binary).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4653 entries, 0 to 4652\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Education                  4653 non-null   object \n",
      " 1   JoiningYear                4653 non-null   int64  \n",
      " 2   City                       4653 non-null   object \n",
      " 3   Age                        4653 non-null   int64  \n",
      " 4   Gender                     4653 non-null   object \n",
      " 5   EverBenched                4653 non-null   object \n",
      " 6   ExperienceInCurrentDomain  4653 non-null   int64  \n",
      " 7   LeaveOrNot                 4653 non-null   int64  \n",
      " 8   Salary                     4653 non-null   float64\n",
      "dtypes: float64(1), int64(4), object(4)\n",
      "memory usage: 327.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84116.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32678.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2014</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>67390.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>73902.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>73780.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  JoiningYear       City  Age  Gender EverBenched  \\\n",
       "0  Bachelors         2017  Bangalore   34    Male          No   \n",
       "1  Bachelors         2013       Pune   28  Female          No   \n",
       "2  Bachelors         2014  New Delhi   38  Female          No   \n",
       "3    Masters         2016  Bangalore   27    Male          No   \n",
       "4    Masters         2017       Pune   24    Male         Yes   \n",
       "\n",
       "   ExperienceInCurrentDomain  LeaveOrNot    Salary  \n",
       "0                          0           0  84116.60  \n",
       "1                          3           1  32678.82  \n",
       "2                          2           0  67390.16  \n",
       "3                          5           1  73902.99  \n",
       "4                          2           1  73780.50  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_df = pd.read_csv('https://raw.githubusercontent.com/FreeDataSets/DataPool/main/employees.csv').drop('Salary') # reading the dataset from a url link\n",
    "# getting a first look at the dataset\n",
    "clf_df.info()\n",
    "clf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>JoiningYear</th>\n",
       "      <td>4653.0</td>\n",
       "      <td>2015.062970</td>\n",
       "      <td>1.863377</td>\n",
       "      <td>2012.00</td>\n",
       "      <td>2013.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>2017.00</td>\n",
       "      <td>2018.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>4653.0</td>\n",
       "      <td>29.393295</td>\n",
       "      <td>4.826087</td>\n",
       "      <td>22.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>41.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <td>4653.0</td>\n",
       "      <td>2.905652</td>\n",
       "      <td>1.558240</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeaveOrNot</th>\n",
       "      <td>4653.0</td>\n",
       "      <td>0.343864</td>\n",
       "      <td>0.475047</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary</th>\n",
       "      <td>4653.0</td>\n",
       "      <td>71909.246063</td>\n",
       "      <td>19564.326975</td>\n",
       "      <td>9697.32</td>\n",
       "      <td>57203.47</td>\n",
       "      <td>75042.99</td>\n",
       "      <td>86188.97</td>\n",
       "      <td>125479.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count          mean           std      min  \\\n",
       "JoiningYear                4653.0   2015.062970      1.863377  2012.00   \n",
       "Age                        4653.0     29.393295      4.826087    22.00   \n",
       "ExperienceInCurrentDomain  4653.0      2.905652      1.558240     0.00   \n",
       "LeaveOrNot                 4653.0      0.343864      0.475047     0.00   \n",
       "Salary                     4653.0  71909.246063  19564.326975  9697.32   \n",
       "\n",
       "                                25%       50%       75%        max  \n",
       "JoiningYear                 2013.00   2015.00   2017.00    2018.00  \n",
       "Age                           26.00     28.00     32.00      41.00  \n",
       "ExperienceInCurrentDomain      2.00      3.00      4.00       7.00  \n",
       "LeaveOrNot                     0.00      0.00      1.00       1.00  \n",
       "Salary                     57203.47  75042.99  86188.97  125479.03  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_df.describe().T # checking wether there are any unusual values in the dataset - \n",
    "# There are no unusual values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y split\n",
    "Xclf = clf_df.drop('LeaveOrNot', axis=1) # features\n",
    "yclf = clf_df['LeaveOrNot'] # target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Features - taken from CHATGPT\n",
    "one_hot_cat_features = [ 'Gender', 'EverBenched'] # features with two categories\n",
    "dummie_vars =  ['Education', 'City',] # features with 3-4 categories\n",
    "\n",
    "Xclf = pd.get_dummies(Xclf, columns=one_hot_cat_features, drop_first=True)\n",
    "Xclf = pd.get_dummies(Xclf, columns=dummie_vars, drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(Xclf, yclf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Exploring the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlQElEQVR4nO3deZwU9ZnH8c/DocghSAADDBEVIgLRAUfQDYkSFQEPjBJXQoJBlGBAV0PEe8Er6opZjQYvgre4XqAogbCo0d2gMCgoeCyoyCHCcAoMwgw8+0f9ZmyGnqkepnsO5vt+vfo13b+q+tXT1dX97Tqm2twdERGRstSp6gJERKT6U1iIiEgshYWIiMRSWIiISCyFhYiIxFJYiIhILIVFCszsQTO7MU19/cDMtppZ3fD4TTO7OB19h/7+ZmYXpqu/csz3VjNbZ2Zfpzj+ODN7KtN17a/K8zqb2TIzO7WUYSeb2cp9rCFt74vQn5tZh3T1lw7hvXpEusetiWp9WIQ30nYz22Jmm8zsn2Y2wsyKl427j3D3W1LsK+mbMqGv5e7e2N13paH2vT5w3b2fuz9e0b7LWccPgNFAZ3f/fpLh+/yBlMK8/xbepFvNrMDMdiY8fjAT8yyljkr9oKuK1zlJDSm9L5JJ95ekhH5/kvD6bwuvy9aE2w/K0194r36e7nErQ7qXcb10dVTDneXu/21mTYGTgHuBnsDQdM7EzOq5e2E6+6wmfgCsd/e1lT1jd+9XdN/MHgNWuvsN5enDzAwwd9+d5vLSribVWhXc/W2gMYCZtQe+AJole9/tx+/HzHD3Wn0DlgGnlmjrAewGuobHjwG3hvstgFeBTcAG4G2iLbQnwzTbga3AGKA94MAwYDnwVkJbvdDfm8DtwFzgG+BloHkYdjLRh99e9QJ9gZ1AQZjfwoT+Lg736wA3AF8Ca4EngKZhWFEdF4ba1gHXl7Gcmobp80J/N4T+Tw3PeXeo47ES0zUqMXwr0AYYBzwX+twCLAZyEqZrA7wY5vcFcHkKr2Xi63RIeJ3ygI3hflbCuG8CtwH/G+rrAPQBPgU2AxOAfxQtyzDNRcDHob+ZwGGh/a2wLLeF5/evJeo6kGh96ZrQ1jLMt9U+1pr4Oh8JvA6sD6/j00QfkInrzLXAR6H/R4EGydax8iz3Esv7ZGAl0RbmWmA1MLSU6W4DdgHfhuV1f2h3YASwJCyvvxAFY5nLv4z62rPne20c8ALwFNF77WKi9/qcML/VwP3AAQl9ONAh4fn+BXiNaJ19FzhyH8ctc11L8nmUG2peA/wpYdgJwD9D/QuBk8taxhX6rEznB29NvJEkLEL7cuDSJG+K24EHgfrh9pOiFbpkXwkr6xNEH5oHJVmB3wRWAV3DOC8CTyW+AUurN6z8T5UY/ibffYhcBCwFjiD6tvUS8GSJ2h4JdR0L7ACOLmU5PUEUZE3CtP8HDCutzhLTJnse48KK3B+oG5brO2FYHWA+8O/AAaH+z4HTY17LxNfpe8B5QMNQ8/PA1BLLaTnQhWgLuyXRm/Hc8PjfiIK4aFkOCMvy6DD8BuCfCf0Vf1CUUtsk4LaExyOBGftYa/0Sr3MH4DSiUGpJFF73lFhnFgHtgOZEoXNrydemvMudvcOiELg51NcfyAcOKWXa4vpLLMNXgWZEW6t5QN9Uln8p82jP3mFRAJwTnutBwHFEH7j1wvgfA1cke13D811P9OFdjyiUny3vuERfOEtd15I8jznAr8P9xsAJ4X7bMI/+4fmcFh63LG0ZV+RW649ZlOErojdWSQVAa6JvNQXu/raHV6YM49x9m7tvL2X4k+6+yN23ATcC5xcdAK+gwUTfQj53961E3y4vMLPE3Y83uft2d19I9M3k2JKdhFouAK519y3uvgy4G/h1Bev7H3ef7tHxmycT5n080Qp/s7vv9Gg/8COhhpS4+3p3f9Hd8919C9E3rZNKjPaYuy/2aFdEP2Cxu78UHv8ZSDxYPwK43d0/DsP/CGSb2WEplvRMifp/GdrKXau7F5R4rkvdfZa773D3POBPSaa/391XuPuG0P+gJDVWdLkXADeH98V0om+0R6U4bZE73H2Tuy8H3gCyQ3tFl3+ROe4+1d13h/V+vru/E5brMuAh9l52iaa4+9xQw9MJ9ZVn3P6Uva6VVAB0MLMW7r7V3d8J7b8Cpof30G53n0W0BdK/zCWwjxQWpWtLtJuppLuIvuH83cw+N7NrUuhrRTmGf0n0zaxFSlWWrU3oL7HvesChCW2JK2k+YX9vCS1CTSX7alvB+krOu0EIssOANuGEg01mtgm4rkTdZTKzhmb2kJl9aWbfEH3bblYihBOXe5vEx+ELQOJB+cOAexPq2QAYqS+DN4CGZtYz7EvPBqbsY60ln+uhZvasma0K0z/F3utPyXWsTZKuKrrc1/uexwBKW5/KUtr6WNHlX2SP5WhmPzSzV83s67Ds/kjZ771U3i9x48atayUNA34IfGJm88zszNB+GPCLEq9XL6Ivs2mnsEjCzI4nWgn/p+Sw8M16tLsfAZwN/N7MTikaXEqXcVse7RLu/4Dom8Q6on3gDRPqqku0myHVfr8iWqES+y4k2u9ZHutCTSX7WpXi9HF1lrQC+MLdmyXcmrh7eb4xjSb6VtvT3Q8GfhrarZS6VgNZRQ/CgeSshOErgN+WqOkgd/9nKsWErafniL7RDwJeDVsR+1JrSX8Mw38Upv9ViWlh73XsqyT9pGO5p2pf1ol9Xv5lzPcB4BOgY1h217H3sku3uHVtD+6+xN0HER3fuhN4wcwaES2TJ0ssk0bufkfRpOksWmGRwMwODqn9LNGxgA+TjHOmmXUIL/BmooNIRWemrCHaz1tevzKzzmbWkGif7wvhw+X/iL5tn2Fm9Yn20x6YMN0aoH3iab4lTAauNLPDzawx0YfKf3k5zwBJ+KC7zcyahE3/3xN9g03FGuB74WyzVMwFtpjZ1WZ2kJnVNbOuIcRT1YToYPAmM2sOjI0Z/zXgR2Z2Tti6GQkkngb8IHCtmXUBMLOmZvaLhOGpvPbPAP9KtHvwmQrUWlITol0+m82sLXBVknFGmllW6P964L+SjJOO5Z6q8r5X4pb/vmpCdPxgq5l1Ai5NQ59x4ta1PZjZr8yspUdnwG0KzbuJ3n9nmdnp4bVqYNFp6kXBs6+fR0kpLCLTzGwLUVJfT7TPt7TTZjsC/0305pwDTHD3N8Kw24EbwibhH8ox/yeJDoh9DTQALgdw983A74CJRN/it7Hn5urz4e96M3svSb+TQt9vEZ3Z8i1wWTnqSnRZmP/nRFtcz4T+Y7n7J0TB9XlYNsl2gSSOvws4k2hXzRdEWzYTic7IStU9RAcw1wHvADNi5rkO+AXwH0QHCTsT7f/dEYZPIfpW92zYXbGI6DhHkXHA4+H5nV/KPN4lWoZtgL/ta61J3AR0J/ry8hrRiQwlPQP8nej1+wy4NUl96VjuqboXGGhmG83sz3Ejp7D899UfiI4fbSE6PpMsRNMqbl1Loi+w2My2Ei23C8LxlhVEB/6vIzoZYAXRF4Wiz/VyLeM4RWfxiEiCsLW2Ehic8GVAJO1qyrqmLQuRIGzONzOzA/lu3/U7MZOJlFtNXNcUFiLfOZFoF8064CzgHC/9dGeRiqhx65p2Q4mISCxtWYiISKz98kKCLVq08Pbt21d1GSIiNcr8+fPXuXvLZMP2y7Bo3749ubm5VV2GiEiNYmZfljZMu6FERCRWxsLCzNqZ2Rtm9pGZLTazfwvt48I1bBaEW/+Eaa41s6Vm9qmZnZ7Q3je0LbXUrsVUI2zatImBAwfSqVMnjj76aObMmQPAuHHjaNu2LdnZ2WRnZzN9+vRyTX/11VdzzDHHMGTIkOJxn3rqKe65555y1Zefn88ZZ5xBp06d6NKlC9dcU/ainzdvHvXq1eOFF17Yo/2bb74hKyuLUaNGFbf17duXY489li5dujBixAh27arwb0GJSCZ5mi5fW/JGdDGr7uF+E6JLV3Qm+k/XPyQZvzPRVU8PBA4nOq2sbrh9RvRv6weEcTqXNe/jjjvOa4IhQ4b4I4884u7uO3bs8I0bN7q7+9ixY/2uu+7ap+k3bdrkp556qru7Dxs2zD/44APPz8/3n/3sZ75z585y1bdt2zZ//fXXi/vv1auXT58+Pem4hYWF3rt3b+/Xr58///zzewy7/PLLfdCgQT5y5Mjits2bN7u7++7du/3cc8/1yZMnl6s2EUk/INcr+xLl7r7a3d8L97cQXSe+rCtEDiC63vsOd/+C6MquPcJtqUeX2d5JdN2mAZmqu7Js3ryZt956i2HDhgFwwAEH0KxZswpPX6dOHQoKCnB38vPzqV+/PuPHj+eyyy6jfv365aqxYcOG9O7du7j/7t27s3Jl8otj3nfffZx33nm0atVqj/b58+ezZs0a+vTps0f7wQcfDEBhYSE7d+4kutSWiFRXlXLMwqJLMncj+rUogFFm9oGZTTKzQ0JbW/a8fPDK0FZae8l5DDezXDPLzcvLS/dTSLsvvviCli1bMnToULp168bFF1/Mtm3biofff//9HHPMMVx00UVs3Lgx5embNGlC//796datG61bt6Zp06a8++67nHPOORWqd9OmTUybNo1TTjllr2GrVq1iypQpXHrpntdg2717N6NHj2b8+PFJ+zz99NNp1aoVTZo0YeDAgRWqT0QyK+NhEa52+iLRr099Q3RJ4COJLla2muhHdCrM3R929xx3z2nZMumZX9VKYWEh7733Hpdeeinvv/8+jRo14o47oisLX3rppXz22WcsWLCA1q1bM3r06HJNP2bMGBYsWMDdd9/NjTfeyM0338zEiRM5//zzufXWva4fl1KtgwYN4vLLL+eII/a+iOUVV1zBnXfeSZ06e65OEyZMoH///mRlJb/68syZM1m9ejU7duzg9ddfL3ddIlJ5MnrqbLis9ovA0+7+EoC7r0kY/gjRzyhCdFXVxGvuZ/Hd7yWU1l5jZWVlkZWVRc+ePQEYOHBg8Yf9oYd+91szl1xyCWeeeWa5pi/y/vvv4+4cddRRXHvttcycOZOhQ4eyZMkSOnbsmHKtw4cPp2PHjlxxxRVJh+fm5nLBBdGPqa1bt47p06dTr1495syZw9tvv82ECRPYunUrO3fupHHjxnvU2aBBAwYMGMDLL7/MaaedlnJNIlK5Mnk2lAF/BT529z8ltCf+itPPiS41DPAK0U9+HmhmhxNdCnwuMA/oGH6T4QCin3h8JVN1V5bvf//7tGvXjk8//RSA2bNn07lzZwBWr15dPN6UKVPo2rVruaYvcuONN3LLLbdQUFBQfLZRnTp1yM/PZ9WqVUl3KZV0ww03sHnz5r3OpJoyZQrXXnstEO0SW7ZsGcuWLWPgwIFMmDCBc845h6effprly5ezbNkyxo8fz5AhQ7jjjjvYunVr8XMsLCzktddeo1OnTqksNhGpIpncsvgx0W80f2hmC0LbdcAgM8sm+hWnZcBvAdx9sZk9B3xE9GtuIz26vj5mNgqYSXRm1CR3X5zBuivNfffdx+DBg9m5cydHHHEEjz76KPDdbiQzo3379jz00EMAfPXVV1x88cXFp9KWNj3A1KlTycnJoU2b6KcjsrOz+dGPfsQxxxzDscceS25uLvXqlf3yr1y5kttuu41OnTrRvXt3AEaNGsXFF1/MZ599VnyQury2bdvG2WefzY4dO9i9eze9e/dmxIgR+9SXiFSO/fJCgjk5OV7R/+Ae/bcn0lRN9fT+tFkc3PJ7HHlC932afvpdD3Ly8F/SsOm+BUZNdXe/IfEjidRQZjbf3XOSDdsvL/ch8bqdVbHjA/2v0paASG2iy32IiEgshYWIiMRSWIiISCyFhYiIxFJYiIhILIWFiIjEUliIiEgshYWIiMRSWIiISCyFhYiIxFJYiIhILIWFiIjEUliIiEgshYWIiMRSWIiISCyFhYiIxFJYiIhILIWFiIjEUliIiEgshYWIiMRSWIiISCyFhYiIxFJYiIhILIWFiIjEUliIiEgshYWIiMRSWIiISCyFhYiIxFJYiIhILIWFiIjEUliIiEgshYWIiMTKWFiYWTsze8PMPjKzxWb2b6G9uZnNMrMl4e8hod3M7M9mttTMPjCz7gl9XRjGX2JmF2aqZhERSS6TWxaFwGh37wycAIw0s87ANcBsd+8IzA6PAfoBHcNtOPAAROECjAV6Aj2AsUUBIyIilSNjYeHuq939vXB/C/Ax0BYYADweRnscOCfcHwA84ZF3gGZm1ho4HZjl7hvcfSMwC+ibqbpFRGRvlXLMwszaA92Ad4FD3X11GPQ1cGi43xZYkTDZytBWWnvJeQw3s1wzy83Ly0vvExARqeUyHhZm1hh4EbjC3b9JHObuDng65uPuD7t7jrvntGzZMh1diohIkNGwMLP6REHxtLu/FJrXhN1LhL9rQ/sqoF3C5FmhrbR2ERGpJJk8G8qAvwIfu/ufEga9AhSd0XQh8HJC+5BwVtQJwOawu2om0MfMDgkHtvuENhERqST1Mtj3j4FfAx+a2YLQdh1wB/CcmQ0DvgTOD8OmA/2BpUA+MBTA3TeY2S3AvDDeze6+IYN1i4hICRkLC3f/H8BKGXxKkvEdGFlKX5OASemrTkREykP/wS0iIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEkthISIisTIWFmY2yczWmtmihLZxZrbKzBaEW/+EYdea2VIz+9TMTk9o7xvalprZNZmqV0RESpfJLYvHgL5J2v/T3bPDbTqAmXUGLgC6hGkmmFldM6sL/AXoB3QGBoVxRUSkEtXLVMfu/paZtU9x9AHAs+6+A/jCzJYCPcKwpe7+OYCZPRvG/Sjd9YqISOmq4pjFKDP7IOymOiS0tQVWJIyzMrSV1i4iIpWossPiAeBIIBtYDdydro7NbLiZ5ZpZbl5eXrq6FRERKjks3H2Nu+9y993AI3y3q2kV0C5h1KzQVlp7sr4fdvccd89p2bJl+osXEanFKjUszKx1wsOfA0VnSr0CXGBmB5rZ4UBHYC4wD+hoZoeb2QFEB8FfqcyaRUQkgwe4zWwycDLQwsxWAmOBk80sG3BgGfBbAHdfbGbPER24LgRGuvuu0M8oYCZQF5jk7oszVbOIiCSXybOhBiVp/msZ498G3JakfTowPY2liYhIOek/uEVEJJbCQkREYqUUFmY2O5U2ERHZP5V5zMLMGgANiQ5SHwJYGHQw+uc4EZFaI+4A92+BK4A2wHy+C4tvgPszV5aIiFQnZYaFu98L3Gtml7n7fZVUk4iIVDMpHbNw9/vM7F/M7JdmNqToluniRKTyffvtt/To0YNjjz2WLl26MHbs2L3Gufzyy2ncuHGZ/SxfvpzGjRszfvx4APLy8ujVqxddu3Zl6tSpxeMNGDCAr776qlw1rl+/nt69e9O4cWNGjRpV6niDBw/mqKOOomvXrlx00UUUFBQAcNddd5GdnU12djZdu3albt26bNiwAYB7772Xrl270qVLF+65555y1bU/S/UA95PAeKAXcHy45WSwLhGpIgceeCCvv/46CxcuZMGCBcyYMYN33nmneHhubi4bN26M7ef3v/89/fr1K348efJkRowYwdy5c4s/hKdNm0a3bt1o06ZNuWps0KABt9xyS3EQlWbw4MF88sknfPjhh2zfvp2JEycCcNVVV7FgwQIWLFjA7bffzkknnUTz5s1ZtGgRjzzyCHPnzmXhwoW8+uqrLF26tFy17a9S/ae8HKCzu3smixGRqmdmxVsNBQUFFBQUYBYdrty1axdXXXUVzzzzDFOmTCm1j6lTp3L44YfTqFGj4rb69euTn5/Pjh07qFu3LoWFhdxzzz1Mmzat3DU2atSIXr16xX6Q9+9f/Ptq9OjRg5UrV+41zuTJkxk0KPof4o8//piePXvSsGFDAE466SReeuklxowZU+4a9zep/p/FIuD7mSxERKqPXbt2kZ2dTatWrTjttNPo2bMnAPfffz9nn302rVu3LnXarVu3cuedd+61++qXv/wlL7/8MqeddhrXXXcdEyZM4Ne//nXxB3MmFRQU8OSTT9K3756/x5afn8+MGTM477zzAOjatStvv/0269evJz8/n+nTp7NixYpkXdY6qW5ZtAA+MrO5wI6iRnc/OyNViUiVqlu3LgsWLGDTpk38/Oc/Z9GiRTRv3pznn3+eN998s8xpx40bx5VXXrnXMY2mTZvy2muvAbBx40buuOMOpkyZwiWXXMLGjRsZPXo0J554Ykaez+9+9zt++tOf8pOf/GSP9mnTpvHjH/+Y5s2bA3D00Udz9dVX06dPHxo1akR2djZ169bNSE01TaphMS6TRYhI9dSsWTN69+7NjBkzOProo1m6dCkdOnQAom/lHTp02GtX0LvvvssLL7zAmDFj2LRpE3Xq1KFBgwZ7HIi+5ZZbuP7665k8eTK9evVi4MCBnHvuucycOTPtz+Gmm24iLy+Phx56aK9hzz77bPEuqCLDhg1j2LBhAFx33XVkZWWlvaaaKKWwcPd/ZLoQEake8vLyqF+/Ps2aNWP79u3MmjWLq6++mjPOOIOvv/66eLzGjRsnPWbw9ttvF98fN27cXmcsLVmyhJUrV3LyySezcOFCGjRogJmxfft2INrVBZR5llNZhgwZwqhRo+jRowcTJ05k5syZzJ49mzp19tzrvnnzZv7xj3/w1FNP7dG+du1aWrVqxfLly3nppZf2OLhfm6UUFma2heiy4gAHAPWBbe5+cKYKE5HSrX0gcwdcF69cy+VP/I1du3ez22HAcUfRY8VbrH3grT3G88KdxXXM+GApC7/8mqvP6rXHONvm/S8cWJ+1D6wtbvvDxFe49uyfsPaBMZy6Yxu/GTuV266+kjFn/pi1D4zh/Rf+m+OPaMvaB5aXWWfODQ+x5dud7Ny1i5eefpz/uuwXHNW6Be+9MYMDOjVi7fwXGDFqPFnND+b4Hx4GwBnZP2R0/38B4Nk5i/jpEYey7Ymb2JbQ79l3P8PGbd9Sr24dbj2vNzsn/5G1SeZfHbW69D8y1reV9wQni06LGACc4O7XZKSqCsrJyfHc3NwK9TH6b0+kqRrZn9zdr3r8e1Emw6KqDZ7wIo8OP4cD6pX/WMGW7Tu48qkZTLxkQAYqq/4qGhZmNt/dk/5bRLmvOuuRqcDpFapKRCSJp3933j4FBUCTgw6stUGRaanuhjo34WEdov+7+DYjFYmISLWT6tlQZyXcLyT6SVTFt4hILZHq2VBDM12IiIhUX6leGyrLzKaY2dpwe9HMdPKxiEgtkeoB7keBV4h+16INMC20iYhILZBqWLR090fdvTDcHgNaZrAuERGpRlINi/Vm9iszqxtuvwLWZ7IwERGpPlINi4uA84GvgdXAQOA3GapJRESqmVRPnb0ZuNDdNwKYWXOiH0O6KFOFiYhI9ZHqlsUxRUEB4O4bgG6ZKUlERKqbVMOijpkdUvQgbFmkulUiIiI1XKof+HcDc8zs+fD4F8BtmSlJRESqm1T/g/sJM8sFfhaaznX3jzJXloiIVCcp70oK4aCAEBGphcp9iXIREal9FBYiIhJLYSEiIrEUFiIiEitjYWFmk8LlzBcltDU3s1lmtiT8PSS0m5n92cyWmtkHZtY9YZoLw/hLzOzCTNUrIiKly+SWxWNA3xJt1wCz3b0jMDs8BugHdAy34cADUPzPf2OBnkAPYGziPweKiEjlyFhYuPtbwIYSzQOAx8P9x4FzEtqf8Mg7QDMzaw2cDsxy9w3hciOz2DuAREQkwyr7mMWh7r463P8aODTcbwusSBhvZWgrrX0vZjbczHLNLDcvLy+9VYuI1HJVdoDb3R3wNPb3sLvnuHtOy5b6XSYRkXSq7LBYE3YvEf6uDe2rgHYJ42WFttLaRUSkElV2WLwCFJ3RdCHwckL7kHBW1AnA5rC7aibQx8wOCQe2+4Q2ERGpRBm7zLiZTQZOBlqY2Uqis5ruAJ4zs2HAl0S/vgcwHegPLAXygaEQ/W6Gmd0CzAvj3Rx+S0NERCpRxsLC3QeVMuiUJOM6MLKUfiYBk9JYmoiIlJP+g1tERGIpLEREJJbCQkREYiksREQklsJCRERiKSxERCSWwkJERGIpLEREJJbCQkREYiksREQklsJCRERiKSxERCSWwkJERGIpLEREJJbCQkREYiksREQklsJCRERiKSxERCSWwkJERGIpLEREJJbCQkREYiksREQklsJCRERiKSxERCSWwkJERGIpLEREJJbCQkREYiksREQklsJCRERiKSxERCSWwkJERGIpLEREJJbCQkREYlVJWJjZMjP70MwWmFluaGtuZrPMbEn4e0hoNzP7s5ktNbMPzKx7VdQsIlKbVeWWRW93z3b3nPD4GmC2u3cEZofHAP2AjuE2HHig0isVEanlqtNuqAHA4+H+48A5Ce1PeOQdoJmZta6C+kREaq2qCgsH/m5m881seGg71N1Xh/tfA4eG+22BFQnTrgxtezCz4WaWa2a5eXl5mapbRKRWqldF8+3l7qvMrBUwy8w+SRzo7m5mXp4O3f1h4GGAnJycck0rIiJlq5ItC3dfFf6uBaYAPYA1RbuXwt+1YfRVQLuEybNCm4iIVJJKDwsza2RmTYruA32ARcArwIVhtAuBl8P9V4Ah4ayoE4DNCburRESkElTFbqhDgSlmVjT/Z9x9hpnNA54zs2HAl8D5YfzpQH9gKZAPDK38kkVEardKDwt3/xw4Nkn7euCUJO0OjKyE0kREpBTV6dRZERGpphQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhJLYSEiIrEUFiIiEkthISIisRQWIiISS2EhIiKxFBYiIhKrxoSFmfU1s0/NbKmZXVPV9YiI1CY1IizMrC7wF6Af0BkYZGadq7YqEZHao0aEBdADWOrun7v7TuBZYEAV1yQiUmvUq+oCUtQWWJHweCXQM3EEMxsODA8Pt5rZp5VUW23QAlhX1UVUB3/iwqouQfam9bPI7+6qaA+HlTagpoRFLHd/GHi4quvYH5lZrrvnVHUdIslo/awcNWU31CqgXcLjrNAmIiKVoKaExTygo5kdbmYHABcAr1RxTSIitUaN2A3l7oVmNgqYCdQFJrn74iouqzbR7j2pzrR+VgJz96quQUREqrmashtKRESqkMJCRERiKSykTLrMilRHZjbJzNaa2aKqrqW2UFhIqXSZFanGHgP6VnURtYnCQsqiy6xIteTubwEbqrqO2kRhIWVJdpmVtlVUi4hUIYWFiIjEUlhIWXSZFREBFBZSNl1mRUQAhYWUwd0LgaLLrHwMPKfLrEh1YGaTgTnAUWa20syGVXVN+ztd7kNERGJpy0JERGIpLEREJJbCQkREYiksREQklsJCRERiKSykRqvoVXHN7CIz+9DMPjCzRWY2ILT/xszapL/iPebdPpWrplb0Cqtm9qaZ5ZRj/MlheVxpZleYWcN9ma/sX2rEz6qKJJNwVdzTiK5bNc/MXnH3j1KcPgu4Huju7pvNrDHQMgz+DbAI+CrthZffY8D9wBOZnpGZfR843t07hMfLgKeA/EzPW6o3bVlITVbRq+K2ArYAWwHcfau7f2FmA4Ec4GkzW2BmB5nZv5vZvLD18bBFjjSz94o6M7OORY/N7Dgz+4eZzTezmWbWOqF9oZktBEamUmQmrrBqZo3CFstcM3u/aIsK+DvQNjzvsUAb4A0zeyOd85eaR2EhNVlFr4q7EFgDfGFmj5rZWQDu/gKQCwx292x33w7c7+7Hu3tX4CDgTHf/DNhsZtmhv6HAo2ZWH7gPGOjuxwGTgNvCOI8Cl7n7sfvwfNPpeuB1d+8B9AbuMrNGwNnAZ+F530S0ZdXb3XtXYa1SDSgspNZy911EP6AzEPg/4D/NbFwpo/c2s3fN7EPgZ0CX0D4RGBp2if0r8AxwFNAVmGVmC4AbgCwzawY0C1sKAE+m/Umlrg9wTajvTaAB8IMqrEeqOR2zkJos9qq4ZtYOmBYePujuDyYO9+h6N3OBuWY2i+ib/7gSfTQAJgA57r4iBEqDMPhFYCzwOjDf3deHA+OL3f3EEv0027enWbYQVPPDw1fc/d9TmQw4z90/LdFX+zSXJ/sJbVlITRZ7VVx3XxF2qWSXDAoza2Nm3ROasoEvw/0tQJNwvygY1oWD4AMT+v+W6EKLDxAFDcCnQEszOzHMp76ZdXH3TcAmM+sVxhucUEtbM5td7iUQ1bAr4TmmEhSEmi8zMwvz71bKeInLQWoxbVlIjeXuhWZWdFXcusCkcl4Vtz4wPmwJfAvkASPCsMeAB81sO3Ai8AjR2VFfE4VUoqeBnxMdHMbdd4aD5H82s6ZE77N7gMVExzUmmZkXjR+0BgqTFRmusHoy0MLMVgJj3f2v5XieAK+ZWUG4PwcYEmr6wMzqAF8AZyaZ7mFghpl9peMWtZuuOitSQWb2B6Cpu99YgT5GAcvdXb8XItWSwkKkAsxsCnAk8DN3X1fV9YhkisJCRERi6QC3iIjEUliIiEgshYWIiMRSWIiISCyFhYiIxPp/ev8r5eH4FU0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  - Plotting the y variable - taken from CHATGPT\n",
    "ax = sns.countplot(x=y_clf_train, palette='Set2');\n",
    "plt.title('Distribution of the Target variable in the Training set');\n",
    "plt.xlabel('0 - Stayed, 1 - Left');\n",
    "# Add percentage labels to the bars - taken from CHATGPT\n",
    "total = len(y_clf_train)\n",
    "for p in ax.patches:\n",
    "    percentage = '{:.1f}%,  {:,}'.format(100 * p.get_height() / total, int(p.get_height()))\n",
    "    x = p.get_x() + p.get_width() / 2 - 0.05\n",
    "    y_height = p.get_height() + 6\n",
    "    ax.annotate(percentage, (x, y_height), fontsize=10, color='black', ha='center');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LeaveOrNot #</th>\n",
       "      <th>LeaveOrNot %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2443</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1279</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LeaveOrNot #  LeaveOrNot %\n",
       "0          2443          0.66\n",
       "1          1279          0.34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our predicted class is clearly imbalanced. We now take care of that\n"
     ]
    }
   ],
   "source": [
    "# showing count values normalized and not normalized \n",
    "display(y_clf_train.value_counts().to_frame().merge(y_clf_train.value_counts(normalize=True).round(2), left_index=True, right_index=True, suffixes=(' #', ' %')));\n",
    "print(\"Our predicted class is clearly imbalanced. We now take care of that\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a method to handel imbalance in our dataset\n",
    "In our specific case, since we're dealing with employee retention prediction, it's likely that identifying employees who leave (the minority class) is crucial for organizations. Therefore, we would use **oversampling algorithm ADASYN**. \n",
    "\n",
    "It is useful for avoiding over-fitting, because it assesses the difficulty of classifying instances within the minority class and generates synthetic samples where they are most needed, enabling a generalization of our classifier. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resampled.shape() vs X_train.shape()\n",
      "(4854, 12)\n",
      "(3722, 12)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN \n",
    "\n",
    "# Instantiate the ADASYN sampler\n",
    "adasyn = ADASYN(random_state=42)\n",
    "\n",
    "# Fit and transform the training data - \n",
    "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_clf_train, y_clf_train)\n",
    "print(\"X_train_resampled.shape() vs X_train.shape()\")\n",
    "print(X_train_resampled.shape)\n",
    "print(X_clf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying XGBoost and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'xgb__eta': 0.5, 'xgb__max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"1/2 XGBOOST CLASSIFIER (RESAMPLED DATA)\"\"\" \n",
    "\n",
    "sc_resmp =StandardScaler().fit(X_train_resampled) # standardizing the resampled data\n",
    "\n",
    "# import pipeline and xgboost\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "# Creating a pipeline \n",
    "xgb_pipeline = Pipeline([\n",
    "                        ('scaler', sc_resmp), \n",
    "                        ('xgb', xgb.XGBClassifier()) # create an XGBoost Classifier\n",
    "                       ])\n",
    "\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid_xgb = {\n",
    "    'xgb__eta': [0.6,0.5,0.1,0.05,0.01],  # Values to search for learning rate\n",
    "    'xgb__max_depth': [2,3,4,5]  # Values to search for max depth\n",
    "}\n",
    "\n",
    "\"\"\" Q6) d)\n",
    "\n",
    "`xgb__eta` - the learning rate, controls the step size at each iteration while moving toward a minimum of the loss function. \n",
    "\n",
    "`xgb__max_depth` - controls the maximum depth of individual trees (base learners) in the gradient boosting ensemble\n",
    "\"\"\"\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "gs_xgb_clf_resmp = GridSearchCV(\n",
    "    xgb_pipeline,          # The pipeline containing the classifier and preprocessing steps\n",
    "    param_grid=param_grid_xgb,\n",
    "    cv=5,              # Number of cross-validation folds\n",
    "    n_jobs=-1,         # Use all available CPU cores for parallelization\n",
    "    verbose=3        # Verbosity level (increase for more details)\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "gs_xgb_clf_resmp.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best hyperparameters and the best model\n",
    "print(\"Best Hyperparameters:\", gs_xgb_clf_resmp.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'rf__max_depth': 10, 'rf__n_estimators': 100}\n",
      "Training Accuracy: 83.46%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\" 2/2 RANDOM FOREST CLASSIFIER (RESAMPLED DATA)\"\"\" \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_resampled_pipeline = Pipeline([('scaler', sc_resmp),('rf', RandomForestClassifier())])\n",
    "\n",
    "# Create the parameter grid\n",
    "rf_clf_param_grid = {'rf__n_estimators': [100, 200], 'rf__max_depth': [3,5,7,10, 20, None] }\n",
    "\n",
    "\"\"\" \n",
    "DEFINING HYPERPARAMETER GRID\n",
    " \n",
    "`rf__n_estimators` -  the number of decision trees that make up the Random Forest, controls the diversity and complexity of the ensemble. A higher number of trees can improve the model's performance up to a point.\n",
    "\n",
    "`max_depth` - Maximum depth of Trees, controls the level of granularity at which the trees can make splits. A deeper tree can capture more complex relationships in the data but is more prone to overfitting\n",
    "\"\"\"\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "rf_resampled_grid_search = GridSearchCV(estimator=rf_resampled_pipeline, param_grid=rf_clf_param_grid, cv=5, n_jobs=-1, verbose=3)\n",
    "          \n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_resampled_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "print(\"Best Hyperparameters: \", rf_resampled_grid_search.best_params_)\n",
    "print(\"Training Accuracy: {:.2f}%\".format(rf_resampled_grid_search.best_score_*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                832       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2945 (11.50 KB)\n",
      "Trainable params: 2945 (11.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the neural network model\n",
    "nn_model_res = keras.Sequential([\n",
    "    layers.Input(shape=(12,)),            # Input layer with 12 features\n",
    "    layers.Dense(64, activation='tanh'),  # Hidden layer with 64 units and tanh activation\n",
    "    layers.Dense(32, activation='tanh'),  # Hidden layer with 32 units and tanh activation\n",
    "    layers.Dense(1, activation='sigmoid') # Output layer with 1 unit (for binary classification) and sigmoid activation\n",
    "]);\n",
    "\n",
    "# Compile the model\n",
    "nn_model_res.compile(optimizer='adam',           # Adam optimizer\n",
    "              loss='binary_crossentropy', # Binary cross-entropy loss (for binary classification)\n",
    "              metrics=['accuracy']);      # Monitor accuracy during training\n",
    "nn_model_res.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The input layer** specifies the shape of the input data, which is (12,) in this case, indicating that there are 12 features.\n",
    "\n",
    "**Two hidden layers** with 64 and 32 units, respectively, are included. These layers use the Tanh activation function, that squashes the output between -1 and 1, providing non-linearity and capturing complex relationships in the data.\n",
    "\n",
    "**The output layer** has a single unit because this is a binary classification problem (sigmoid activation function).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7250\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7567\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7750\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7773\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7841\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7981\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7998\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8103\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8105\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8115\n"
     ]
    }
   ],
   "source": [
    "X_clf_train_transformed_resampled = sc_resmp.transform(X_train_resampled) # scaling the test data with the same scaler that was used for the training data\n",
    "\n",
    "# fitting the NN on the resampled data\n",
    "nn_model_res.fit(X_clf_train_transformed_resampled, y_train_resampled,  epochs=10, batch_size=32, verbose=1); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "XGboost - Pre-Resampled Data :\n",
      "TRAIN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.99      0.79      2443\n",
      "           1       0.71      0.03      0.06      1279\n",
      "\n",
      "    accuracy                           0.66      3722\n",
      "   macro avg       0.69      0.51      0.42      3722\n",
      "weighted avg       0.68      0.66      0.54      3722\n",
      "\n",
      "TEST:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79       610\n",
      "           1       0.77      0.03      0.06       321\n",
      "\n",
      "    accuracy                           0.66       931\n",
      "   macro avg       0.72      0.51      0.43       931\n",
      "weighted avg       0.70      0.66      0.54       931\n",
      "\n",
      "====================================================================== \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Random Forest - Pre-Resampled Data :\n",
      "TRAIN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      2443\n",
      "           1       0.66      0.53      0.59      1279\n",
      "\n",
      "    accuracy                           0.75      3722\n",
      "   macro avg       0.72      0.69      0.70      3722\n",
      "weighted avg       0.74      0.75      0.74      3722\n",
      "\n",
      "TEST:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       610\n",
      "           1       0.73      0.56      0.64       321\n",
      "\n",
      "    accuracy                           0.78       931\n",
      "   macro avg       0.76      0.73      0.74       931\n",
      "weighted avg       0.77      0.78      0.77       931\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "117/117 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "======================================================================\n",
      "Neural Network - Pre-Resampled Data :\n",
      "TRAIN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      2443\n",
      "           1       0.83      0.63      0.72      1279\n",
      "\n",
      "    accuracy                           0.83      3722\n",
      "   macro avg       0.83      0.78      0.80      3722\n",
      "weighted avg       0.83      0.83      0.82      3722\n",
      "\n",
      "TEST:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       610\n",
      "           1       0.87      0.67      0.76       321\n",
      "\n",
      "    accuracy                           0.85       931\n",
      "   macro avg       0.86      0.81      0.82       931\n",
      "weighted avg       0.85      0.85      0.85       931\n",
      "\n",
      "====================================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_clf_test_transformed_resmp = sc_resmp.transform(X_clf_test) # sacling the test data using the fitted scaler\n",
    "\n",
    "\n",
    "\n",
    "# creating a function to print the classification report for each model - \n",
    "def model_classification_report(model_name ,model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This function takes in a model, training and test data and returns the classification report for the model\n",
    "    \"\"\"\n",
    "    # Make predictions on the transformed test data using the fitted model\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Generate classification reports for each model\n",
    "    report_train = classification_report(y_train, y_pred_train.round())\n",
    "    report_test = classification_report(y_test, y_pred_test.round())\n",
    "    # print the name of the model\n",
    "    print(\"=\"*70)\n",
    "    print(model_name,\":\")\n",
    "    # Print the classification report for each model\n",
    "    print(\"TRAIN:\\n\", report_train)\n",
    "    print(\"TEST:\\n\", report_test)\n",
    "    print(\"=\"*70, \"\\n\")\n",
    "    # print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "XGboost - Resampled Data :\n",
      "TRAIN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.09      0.16      2443\n",
      "           1       0.50      0.93      0.65      2411\n",
      "\n",
      "    accuracy                           0.51      4854\n",
      "   macro avg       0.54      0.51      0.40      4854\n",
      "weighted avg       0.54      0.51      0.40      4854\n",
      "\n",
      "TEST:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.10      0.17       610\n",
      "           1       0.33      0.84      0.47       321\n",
      "\n",
      "    accuracy                           0.36       931\n",
      "   macro avg       0.44      0.47      0.32       931\n",
      "weighted avg       0.47      0.36      0.27       931\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "======================================================================"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest - Resampled Data :\n",
      "TRAIN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      2443\n",
      "           1       0.78      0.66      0.72      2411\n",
      "\n",
      "    accuracy                           0.74      4854\n",
      "   macro avg       0.74      0.74      0.74      4854\n",
      "weighted avg       0.74      0.74      0.74      4854\n",
      "\n",
      "TEST:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       610\n",
      "           1       0.63      0.57      0.60       321\n",
      "\n",
      "    accuracy                           0.74       931\n",
      "   macro avg       0.71      0.70      0.70       931\n",
      "weighted avg       0.73      0.74      0.74       931\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "152/152 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "======================================================================\n",
      "Neural Network - Resampled Data :\n",
      "TRAIN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      2443\n",
      "           1       0.90      0.72      0.80      2411\n",
      "\n",
      "    accuracy                           0.82      4854\n",
      "   macro avg       0.83      0.82      0.82      4854\n",
      "weighted avg       0.83      0.82      0.82      4854\n",
      "\n",
      "TEST:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       610\n",
      "           1       0.87      0.64      0.74       321\n",
      "\n",
      "    accuracy                           0.84       931\n",
      "   macro avg       0.85      0.79      0.81       931\n",
      "weighted avg       0.85      0.84      0.83       931\n",
      "\n",
      "====================================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the classification report for each model trained on the resampled data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "model_classification_report(\"XGboost - Resampled Data\", gs_xgb_clf_resmp, X_clf_train_transformed_resampled, y_train_resampled, X_clf_test_transformed_resmp, y_clf_test)\n",
    "model_classification_report(\"Random Forest - Resampled Data\", rf_resampled_grid_search, X_clf_train_transformed_resampled, y_train_resampled, X_clf_test_transformed_resmp, y_clf_test)\n",
    "model_classification_report(\"Neural Network - Resampled Data\", nn_model_res, X_clf_train_transformed_resampled, y_train_resampled, X_clf_test_transformed_resmp, y_clf_test)\n",
    "\n",
    "# stop ignoring UserWarning warnings\n",
    "warnings.filterwarnings('default', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Neural Network model preformed with the best `Accuracy`. It has the highest accuracy on both the training and test sets. All models preformed fine without overfitting or underfitting significantly.\n",
    "\n",
    "**`Recall`** measures the proportion of true positives among all the actual positives (employees who left) In the context of employee retention, high recall means that the model is effective at identifying employees who are likely to leave, minimizing missed opportunities for retention efforts.\n",
    "\n",
    "Based on the **`Recall`**, XGboost preformed the best on the resampled test set, so it should be considered as the most suited model."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
