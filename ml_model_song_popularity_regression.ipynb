{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Little Regression Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing general python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# importing libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# importing libraries for data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# importing libraries for model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# importing libraries for model evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,mean_absolute_percentage_error\n",
    "\n",
    "# importing libraries for model tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# importing tensorflow libraries for deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset - Spotify Songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "\n",
    "In this task, we will use a sample of 150K records, out of the [\"Spotify Dataset 1921-2020, 600k+ Tracks\"](https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-19212020-600k-tracks?select=tracks.csv) which is available on kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The columns:\n",
    "\n",
    ">**Target Column** we will predict the following column:\n",
    "- `popularity` (Ranges from 0 to 100), float, representing the popularity of the song in the Spotify platform.\n",
    "\n",
    ">**Numerical Columns**:\n",
    "- `id` (Id of tracks generated by Spotify)\n",
    "- `acousticness` (Ranges from 0 to 1)\n",
    "- `danceability` (Ranges from 0 to 1)\n",
    "- `energy` (Ranges from 0 to 1)\n",
    "- `duration_ms` (Integer typically ranging from 200k to 300k)\n",
    "- `instrumentalness` (Ranges from 0 to 1)\n",
    "- `valence` (Ranges from 0 to 1)\n",
    "- `animality` (Ranges from 0 to 1)\n",
    "- `tempo` (Float typically ranging from 50 to 150)\n",
    "- `liveness` (Ranges from 0 to 1)\n",
    "- `loudness` (Float typically ranging from -60 to 0)\n",
    "- `speechiness` (Ranges from 0 to 1)\n",
    "- `release_year` a column which we are going to extract out of the `Release` column and predict based on song's features.\n",
    "\n",
    "\n",
    "> **Categorical Columns** (string types):\n",
    "- `explicit` (Whether the song is explicit (contains swearing or inappropriate language) or not)\n",
    "  \n",
    "> The following categorical columns will be removed to simplify the task (to many categories):\n",
    "- `artists` (List of artists mentioned)\n",
    "- `track_name` (Name of the song)\n",
    "- `genre` is the genre of the song. String type, Multiclass.<br>\n",
    "- `key` (All keys on octave encoded as values ranging from 0 to 11, starting on C as 0, C# as 1, and so on…)\n",
    "- `time_signature` A notational convention to specify how many beats are in each bar (or measure). For example, rock music often has a time signature of 4/4, while classical music often has a time signature of 3/4 or 4/4.\n",
    "- `Release` the date which the song was released on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   id                150000 non-null  object \n",
      " 1   name              149984 non-null  object \n",
      " 2   popularity        150000 non-null  int64  \n",
      " 3   duration_ms       150000 non-null  int64  \n",
      " 4   explicit          150000 non-null  int64  \n",
      " 5   artists           150000 non-null  object \n",
      " 6   release_date      150000 non-null  object \n",
      " 7   danceability      150000 non-null  float64\n",
      " 8   energy            150000 non-null  float64\n",
      " 9   key               150000 non-null  int64  \n",
      " 10  loudness          150000 non-null  float64\n",
      " 11  speechiness       150000 non-null  float64\n",
      " 12  acousticness      150000 non-null  float64\n",
      " 13  instrumentalness  150000 non-null  float64\n",
      " 14  liveness          150000 non-null  float64\n",
      " 15  valence           150000 non-null  float64\n",
      " 16  tempo             150000 non-null  float64\n",
      " 17  time_signature    150000 non-null  int64  \n",
      "dtypes: float64(9), int64(5), object(4)\n",
      "memory usage: 20.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6ot2x31QPJlJ4f6AM2yHlT</td>\n",
       "      <td>Amigo Mío (Homenaje a Juan Gabriel)</td>\n",
       "      <td>25</td>\n",
       "      <td>219907</td>\n",
       "      <td>0</td>\n",
       "      <td>['Ana Gabriel']</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.282</td>\n",
       "      <td>7</td>\n",
       "      <td>-14.247</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.549</td>\n",
       "      <td>126.041</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ooilm0qewfPaWkY93uEQ4</td>\n",
       "      <td>Ca C'est Gentil Ca C'est Pas Mal</td>\n",
       "      <td>0</td>\n",
       "      <td>181427</td>\n",
       "      <td>0</td>\n",
       "      <td>['Pierrette Mad']</td>\n",
       "      <td>1925</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.863</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.861</td>\n",
       "      <td>89.963</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1FlNozP5jet4DrGU2Ava1l</td>\n",
       "      <td>เหมือนไม่เคย</td>\n",
       "      <td>8</td>\n",
       "      <td>181560</td>\n",
       "      <td>0</td>\n",
       "      <td>['สุเทพ วงศ์กำแหง']</td>\n",
       "      <td>1992-04-01</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.312</td>\n",
       "      <td>8</td>\n",
       "      <td>-17.238</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.526</td>\n",
       "      <td>95.032</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2KP3zqq9MQarh2WwsuonoM</td>\n",
       "      <td>Menino Bonito</td>\n",
       "      <td>50</td>\n",
       "      <td>166333</td>\n",
       "      <td>0</td>\n",
       "      <td>['Rita Lee']</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.775</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.253</td>\n",
       "      <td>178.251</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4mKNBGNpDA7Ldu0fSyb7MX</td>\n",
       "      <td>Lekkerkry</td>\n",
       "      <td>31</td>\n",
       "      <td>191000</td>\n",
       "      <td>0</td>\n",
       "      <td>['ZAK VAN NIEKERK']</td>\n",
       "      <td>2014-03-28</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.844</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.548</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.911</td>\n",
       "      <td>168.093</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                 name  popularity  \\\n",
       "0  6ot2x31QPJlJ4f6AM2yHlT  Amigo Mío (Homenaje a Juan Gabriel)          25   \n",
       "1  5ooilm0qewfPaWkY93uEQ4     Ca C'est Gentil Ca C'est Pas Mal           0   \n",
       "2  1FlNozP5jet4DrGU2Ava1l                         เหมือนไม่เคย           8   \n",
       "3  2KP3zqq9MQarh2WwsuonoM                        Menino Bonito          50   \n",
       "4  4mKNBGNpDA7Ldu0fSyb7MX                            Lekkerkry          31   \n",
       "\n",
       "   duration_ms  explicit              artists release_date  danceability  \\\n",
       "0       219907         0      ['Ana Gabriel']         1991         0.673   \n",
       "1       181427         0    ['Pierrette Mad']         1925         0.520   \n",
       "2       181560         0  ['สุเทพ วงศ์กำแหง']   1992-04-01         0.654   \n",
       "3       166333         0         ['Rita Lee']   1974-01-01         0.247   \n",
       "4       191000         0  ['ZAK VAN NIEKERK']   2014-03-28         0.663   \n",
       "\n",
       "   energy  key  loudness  speechiness  acousticness  instrumentalness  \\\n",
       "0   0.282    7   -14.247       0.0428         0.454          0.000000   \n",
       "1   0.359    0   -11.863       0.0817         0.988          0.000000   \n",
       "2   0.312    8   -17.238       0.0305         0.662          0.598000   \n",
       "3   0.426    0    -7.775       0.0316         0.725          0.000000   \n",
       "4   0.844    7    -4.548       0.0528         0.080          0.000005   \n",
       "\n",
       "   liveness  valence    tempo  time_signature  \n",
       "0     0.118    0.549  126.041               4  \n",
       "1     0.106    0.861   89.963               4  \n",
       "2     0.106    0.526   95.032               4  \n",
       "3     0.160    0.253  178.251               4  \n",
       "4     0.176    0.911  168.093               4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_url = 'https://raw.githubusercontent.com/FreeDataSets/DataPool/main/tracks_150000.csv' # this is the url for the dataset\n",
    "reg_df = pd.read_csv(reg_url)#.sample(100000,random_state=42) # In order to reduce the size of the dataset, we are taking a random sample of 5000 rows from the dataset\n",
    "\n",
    "# a preview of the dataframe\n",
    "reg_df.info() \n",
    "reg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6ot2x31QPJlJ4f6AM2yHlT</td>\n",
       "      <td>Amigo Mío (Homenaje a Juan Gabriel)</td>\n",
       "      <td>25</td>\n",
       "      <td>219907</td>\n",
       "      <td>0</td>\n",
       "      <td>['Ana Gabriel']</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.282</td>\n",
       "      <td>7</td>\n",
       "      <td>-14.247</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.549</td>\n",
       "      <td>126.041</td>\n",
       "      <td>4</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ooilm0qewfPaWkY93uEQ4</td>\n",
       "      <td>Ca C'est Gentil Ca C'est Pas Mal</td>\n",
       "      <td>0</td>\n",
       "      <td>181427</td>\n",
       "      <td>0</td>\n",
       "      <td>['Pierrette Mad']</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.863</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.861</td>\n",
       "      <td>89.963</td>\n",
       "      <td>4</td>\n",
       "      <td>1925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1FlNozP5jet4DrGU2Ava1l</td>\n",
       "      <td>เหมือนไม่เคย</td>\n",
       "      <td>8</td>\n",
       "      <td>181560</td>\n",
       "      <td>0</td>\n",
       "      <td>['สุเทพ วงศ์กำแหง']</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.312</td>\n",
       "      <td>8</td>\n",
       "      <td>-17.238</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.526</td>\n",
       "      <td>95.032</td>\n",
       "      <td>4</td>\n",
       "      <td>1992</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2KP3zqq9MQarh2WwsuonoM</td>\n",
       "      <td>Menino Bonito</td>\n",
       "      <td>50</td>\n",
       "      <td>166333</td>\n",
       "      <td>0</td>\n",
       "      <td>['Rita Lee']</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.775</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.253</td>\n",
       "      <td>178.251</td>\n",
       "      <td>4</td>\n",
       "      <td>1974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4mKNBGNpDA7Ldu0fSyb7MX</td>\n",
       "      <td>Lekkerkry</td>\n",
       "      <td>31</td>\n",
       "      <td>191000</td>\n",
       "      <td>0</td>\n",
       "      <td>['ZAK VAN NIEKERK']</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.844</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.548</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.911</td>\n",
       "      <td>168.093</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                 name  popularity  \\\n",
       "0  6ot2x31QPJlJ4f6AM2yHlT  Amigo Mío (Homenaje a Juan Gabriel)          25   \n",
       "1  5ooilm0qewfPaWkY93uEQ4     Ca C'est Gentil Ca C'est Pas Mal           0   \n",
       "2  1FlNozP5jet4DrGU2Ava1l                         เหมือนไม่เคย           8   \n",
       "3  2KP3zqq9MQarh2WwsuonoM                        Menino Bonito          50   \n",
       "4  4mKNBGNpDA7Ldu0fSyb7MX                            Lekkerkry          31   \n",
       "\n",
       "   duration_ms  explicit              artists  danceability  energy  key  \\\n",
       "0       219907         0      ['Ana Gabriel']         0.673   0.282    7   \n",
       "1       181427         0    ['Pierrette Mad']         0.520   0.359    0   \n",
       "2       181560         0  ['สุเทพ วงศ์กำแหง']         0.654   0.312    8   \n",
       "3       166333         0         ['Rita Lee']         0.247   0.426    0   \n",
       "4       191000         0  ['ZAK VAN NIEKERK']         0.663   0.844    7   \n",
       "\n",
       "   loudness  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "0   -14.247       0.0428         0.454          0.000000     0.118    0.549   \n",
       "1   -11.863       0.0817         0.988          0.000000     0.106    0.861   \n",
       "2   -17.238       0.0305         0.662          0.598000     0.106    0.526   \n",
       "3    -7.775       0.0316         0.725          0.000000     0.160    0.253   \n",
       "4    -4.548       0.0528         0.080          0.000005     0.176    0.911   \n",
       "\n",
       "     tempo  time_signature  release_year  release_month  \n",
       "0  126.041               4          1991              1  \n",
       "1   89.963               4          1925              1  \n",
       "2   95.032               4          1992              4  \n",
       "3  178.251               4          1974              1  \n",
       "4  168.093               4          2014              3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert Release to date and then extract year from it \n",
    "reg_df['release_date'] = pd.to_datetime(reg_df['release_date'])\n",
    "reg_df['release_year'] = reg_df['release_date'].dt.year\n",
    "reg_df['release_month'] = reg_df['release_date'].dt.month\n",
    "reg_df.drop('release_date', axis=1, inplace=True) \n",
    "reg_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   popularity        150000 non-null  int64  \n",
      " 1   duration_ms       150000 non-null  int64  \n",
      " 2   explicit          150000 non-null  int64  \n",
      " 3   danceability      150000 non-null  float64\n",
      " 4   energy            150000 non-null  float64\n",
      " 5   key               150000 non-null  int64  \n",
      " 6   loudness          150000 non-null  float64\n",
      " 7   speechiness       150000 non-null  float64\n",
      " 8   acousticness      150000 non-null  float64\n",
      " 9   instrumentalness  150000 non-null  float64\n",
      " 10  liveness          150000 non-null  float64\n",
      " 11  valence           150000 non-null  float64\n",
      " 12  tempo             150000 non-null  float64\n",
      " 13  time_signature    150000 non-null  int64  \n",
      " 14  release_year      150000 non-null  int64  \n",
      " 15  release_month     150000 non-null  int64  \n",
      "dtypes: float64(9), int64(7)\n",
      "memory usage: 18.3 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>219907</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.282</td>\n",
       "      <td>7</td>\n",
       "      <td>-14.247</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.549</td>\n",
       "      <td>126.041</td>\n",
       "      <td>4</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>181427</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.863</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.861</td>\n",
       "      <td>89.963</td>\n",
       "      <td>4</td>\n",
       "      <td>1925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>181560</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.312</td>\n",
       "      <td>8</td>\n",
       "      <td>-17.238</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.526</td>\n",
       "      <td>95.032</td>\n",
       "      <td>4</td>\n",
       "      <td>1992</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  duration_ms  explicit  danceability  energy  key  loudness  \\\n",
       "0          25       219907         0         0.673   0.282    7   -14.247   \n",
       "1           0       181427         0         0.520   0.359    0   -11.863   \n",
       "2           8       181560         0         0.654   0.312    8   -17.238   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       0.0428         0.454             0.000     0.118    0.549  126.041   \n",
       "1       0.0817         0.988             0.000     0.106    0.861   89.963   \n",
       "2       0.0305         0.662             0.598     0.106    0.526   95.032   \n",
       "\n",
       "   time_signature  release_year  release_month  \n",
       "0               4          1991              1  \n",
       "1               4          1925              1  \n",
       "2               4          1992              4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reg_df.drop(['name', 'artists','id','release_date', 'artists_id','genre',], axis=1, inplace=True, errors='ignore') # Removing Categorical features with more then 10 unique values\n",
    "reg_df.info()\n",
    "reg_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target variable \n",
    "Xreg = reg_df.drop('popularity', axis=1) # features\n",
    "yreg = reg_df['popularity'] # target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we standardize the data as asked in question 9, although it creates a problem of data leakage as we are using the test data to fit the scaler\n",
    "scaler_reg = StandardScaler().fit(Xreg)\n",
    "Xreg_scaled = scaler_reg.transform(Xreg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "Xreg_train_scaled, Xreg_test_scaled, yreg_train, yreg_test = train_test_split(Xreg, yreg, test_size=0.2, random_state=42)\n",
    "# end of Q9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear Regression object\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "lin_reg.fit(Xreg_train_scaled, yreg_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper function to save and compare regression metrics \n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,mean_absolute_percentage_error\n",
    "\n",
    "def calculate_and_append_metrics(model_name, model, X_train, y_train, X_test, y_test, train_results_df, test_results_df):\n",
    "    # Calculate metrics for the training dataset\n",
    "    train_metrics = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'R2 Score': [r2_score(y_train, model.predict(X_train))],\n",
    "        'RMSE': [mean_squared_error(y_train, model.predict(X_train), squared=False)],\n",
    "        'MAE': [mean_absolute_error(y_train, model.predict(X_train))],\n",
    "        'MAPE': [mean_absolute_percentage_error(y_train, model.predict(X_train))]\n",
    "    })\n",
    "\n",
    "    # Calculate metrics for the test dataset\n",
    "    test_metrics = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'R2 Score': [r2_score(y_test, model.predict(X_test))],\n",
    "        'RMSE': [mean_squared_error(y_test, model.predict(X_test), squared=False)],\n",
    "        'MAE': [mean_absolute_error(y_test, model.predict(X_test))],\n",
    "        'MAPE': [mean_absolute_percentage_error(y_test, model.predict(X_test))]\n",
    "    })\n",
    "\n",
    "    # Concatenate metrics to the respective DataFrames\n",
    "    train_results_df = pd.concat([train_results_df, train_metrics], ignore_index=True)\n",
    "    test_results_df = pd.concat([test_results_df, test_metrics], ignore_index=True)\n",
    "\n",
    "    return train_results_df, test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.379368</td>\n",
       "      <td>14.476721</td>\n",
       "      <td>11.146972</td>\n",
       "      <td>4.020286e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.379368  14.476721  11.146972  4.020286e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.364608</td>\n",
       "      <td>14.69266</td>\n",
       "      <td>11.293555</td>\n",
       "      <td>4.288415e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score      RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.364608  14.69266  11.293555  4.288415e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model using the train and test set and different metrics\n",
    "\n",
    "# Create empty DataFrames to store the results\n",
    "train_results_df = pd.DataFrame()\n",
    "test_results_df = pd.DataFrame()\n",
    "\n",
    "# Calculate metrics for the Linear Regression model\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('Linear Regression', lin_reg, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "# display the results\n",
    "print(\"Train:\")\n",
    "display(train_results_df)\n",
    "print(\"-\"*70,\"\\n\")\n",
    "print(\"Test:\")\n",
    "display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END .................poly__degree=1;, score=-206.531 total time=   0.2s\n",
      "[CV 2/5] END .................poly__degree=1;, score=-206.173 total time=   0.2s\n",
      "[CV 3/5] END .................poly__degree=1;, score=-216.114 total time=   0.2s\n",
      "[CV 4/5] END .................poly__degree=1;, score=-215.903 total time=   0.2s\n",
      "[CV 5/5] END .................poly__degree=1;, score=-208.563 total time=   0.1s\n",
      "[CV 1/5] END poly__degree=2;, score=-3131972794266936944945889542144.000 total time=   5.6s\n",
      "[CV 2/5] END poly__degree=2;, score=-808172469643618347048415264768.000 total time=   6.3s\n",
      "[CV 3/5] END poly__degree=2;, score=-22831770557919225161254705299456.000 total time=   5.4s\n",
      "[CV 4/5] END poly__degree=2;, score=-45645405942783020445248385974272.000 total time=   4.1s\n",
      "[CV 5/5] END poly__degree=2;, score=-3095176959895833735432050311168.000 total time=   4.4s\n",
      "[CV 1/5] END poly__degree=3;, score=-449874951557239091151082787258692529257357246464.000 total time=  53.1s\n",
      "[CV 2/5] END poly__degree=3;, score=-294809138764618351902931333850291147954123882627072.000 total time=  53.3s\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Ridge Regression \"\"\"\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = Xreg_train_scaled\n",
    "y = yreg_train\n",
    "\n",
    "# Define the degrees to consider in the polynomial features\n",
    "degrees = range(1, 5)\n",
    "\n",
    "# Create a RidgeCV model with cross-validation\n",
    "ridge_cv = RidgeCV([0.01, 0.1, 1, 10])\n",
    "\n",
    "# Create a PolynomialFeatures transformer\n",
    "poly = PolynomialFeatures()\n",
    "\n",
    "# Perform a grid search over polynomial degrees\n",
    "param_grid = {'poly__degree': degrees}\n",
    "\n",
    "# Create a pipeline that combines PolynomialFeatures and RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('poly', poly),('ridge_cv', ridge_cv)])\n",
    "\n",
    "# Use GridSearchCV to find the best polynomial degree\n",
    "ridge_grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error',verbose=3)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "ridge_grid_search.fit(X, y)\n",
    "warnings.filterwarnings(\"default\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "# Get the best polynomial degree and the best alpha for RidgeCV\n",
    "best_degree = ridge_grid_search.best_params_['poly__degree']\n",
    "best_alpha = ridge_grid_search.best_estimator_.named_steps['ridge_cv'].alpha_\n",
    "\n",
    "# Print the results\n",
    "print(\"RidgeCV Results:\")\n",
    "print(\"Best Polynomial Degree:\", best_degree)\n",
    "print(\"Best Alpha for RidgeCV:\", best_alpha)\n",
    "print(\"Best Negative MSE:\", (-ridge_grid_search.best_score_)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END .................poly__degree=1;, score=-257.047 total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .................poly__degree=1;, score=-265.037 total time=   0.5s\n",
      "[CV 3/5] END .................poly__degree=1;, score=-258.524 total time=   0.6s\n",
      "[CV 4/5] END .................poly__degree=1;, score=-264.408 total time=   0.4s\n",
      "[CV 5/5] END .................poly__degree=1;, score=-267.163 total time=   0.5s\n",
      "[CV 1/5] END .................poly__degree=2;, score=-239.092 total time=  35.9s\n",
      "[CV 2/5] END .................poly__degree=2;, score=-243.711 total time=  32.6s\n",
      "[CV 3/5] END .................poly__degree=2;, score=-238.257 total time=  32.0s\n",
      "[CV 4/5] END .................poly__degree=2;, score=-242.802 total time=  31.4s\n",
      "[CV 5/5] END .................poly__degree=2;, score=-244.565 total time=  27.9s\n",
      "/nLassoCV Results:\n",
      "Best Polynomial Degree: 2\n",
      "Best Polynomial Degree: 2\n",
      "Best Alpha for LassoCV: 0.01\n",
      "Best RMSE: 15.546236945399754\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Lasso Regression\"\"\"\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = Xreg_train_scaled\n",
    "y = yreg_train\n",
    "\n",
    "# Define the degrees to consider in the polynomial features\n",
    "last_degree = 3\n",
    "degrees = range(1, last_degree)\n",
    "\n",
    "# Create a LassoCV model with cross-validation\n",
    "lasso_cv = LassoCV(alphas=[0.01,0.1, 1.0, 10.0]\n",
    "                #    max_iter=100000\n",
    "                   )\n",
    "\n",
    "# Create a PolynomialFeatures transformer\n",
    "poly = PolynomialFeatures()\n",
    "\n",
    "# Perform a grid search over polynomial degrees\n",
    "param_grid = {'poly__degree': degrees}\n",
    "\n",
    "# Create a pipeline that combines PolynomialFeatures and LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('poly', poly),\n",
    "    ('lasso_cv', lasso_cv)\n",
    "])\n",
    "\n",
    "# Use GridSearchCV to find the best polynomial degree\n",
    "lasso_grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Filter out ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "lasso_grid_search.fit(X, y)\n",
    "\n",
    "# Optionally, you can reset the warning filters to their original state\n",
    "warnings.filterwarnings(\"default\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "# Get the best polynomial degree and the best alpha for LassoCV\n",
    "best_degree = lasso_grid_search.best_params_['poly__degree']\n",
    "best_alpha = lasso_grid_search.best_estimator_.named_steps['lasso_cv'].alpha_\n",
    "best_degree = lasso_grid_search.best_params_['poly__degree']\n",
    "\n",
    "# Print the results\n",
    "print(\"/nLassoCV Results:\")\n",
    "print(\"Best Polynomial Degree:\", best_degree)\n",
    "print(\"Best Polynomial Degree:\", best_degree)\n",
    "print(\"Best Alpha for LassoCV:\", best_alpha)\n",
    "print(\"Best RMSE:\", (-lasso_grid_search.best_score_)**0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Words About Regularization\n",
    "\n",
    "The problem with a complex model of second order or higher is the risk of **Overfitting:**\n",
    "\n",
    "When a model fits the *noise* and random fluctuations in the training data rather than capturing the underlying patterns that are truly representative of the target population. \n",
    "\n",
    "A *solution* to the overfitting risk is **Regularization**: \n",
    "Adding a penalty term to the model's *loss function*, encouraging the model to have smaller parameter values or simpler parameter patterns, discourages overfitting.\n",
    "\n",
    "**Lasso (Least Absolute Shrinkage and Selection Operator):** adds a penalty term $||β||_1$ which is the sum of the absolute values of the coefficients.\n",
    "**Ridge** adds a penalty term $||β||_2^2$ which is the sum of the squared values of the coefficients.\n",
    "Lasso is better for Feature Selection and ridge is better for datasets with Multicollinearity, because Lasso tends to drive the coefficients of irrelevant features to exactly zero, effectively performing feature selection, while Ridge doesn't. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating polynomial regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.226271</td>\n",
       "      <td>16.195170</td>\n",
       "      <td>13.142729</td>\n",
       "      <td>6.466474e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.226174</td>\n",
       "      <td>16.196175</td>\n",
       "      <td>13.142202</td>\n",
       "      <td>6.465996e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.288222</td>\n",
       "      <td>15.533286</td>\n",
       "      <td>12.533719</td>\n",
       "      <td>5.489350e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.226271  16.195170  13.142729  6.466474e+15\n",
       "1            RidgeCV  0.226174  16.196175  13.142202  6.465996e+15\n",
       "2            LassoCV  0.288222  15.533286  12.533719  5.489350e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.232768</td>\n",
       "      <td>16.048065</td>\n",
       "      <td>12.964561</td>\n",
       "      <td>6.245663e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.232843</td>\n",
       "      <td>16.047280</td>\n",
       "      <td>12.963581</td>\n",
       "      <td>6.245130e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.294826</td>\n",
       "      <td>15.385355</td>\n",
       "      <td>12.397866</td>\n",
       "      <td>5.342149e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.232768  16.048065  12.964561  6.245663e+15\n",
       "1            RidgeCV  0.232843  16.047280  12.963581  6.245130e+15\n",
       "2            LassoCV  0.294826  15.385355  12.397866  5.342149e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model using the train and test set and different metrics\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('RidgeCV', ridge_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('LassoCV', lasso_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "# display the results\n",
    "print(\"Train:\")\n",
    "display(train_results_df)\n",
    "print(\"-\"*70,\"\\n\")\n",
    "print(\"Test:\")\n",
    "display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying RandomForrestRegressor and Xgbregressor\n",
    "We will use pre-tuned xgb and rf models and also hyperparameter tuned xgb and rf models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(Xreg_train_scaled, yreg_train)\n",
    "\n",
    "# run Xgboost regressor\n",
    "import xgboost as xgb\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "xgb_reg.fit(Xreg_train_scaled, yreg_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-266.155 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-271.410 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-264.962 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-270.650 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-271.987 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-248.734 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-253.972 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-247.566 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-253.800 total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-254.690 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-259.528 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-264.696 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-258.152 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-263.722 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-265.452 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-241.560 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-246.938 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-240.295 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-246.338 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-247.390 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-254.799 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-259.750 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-253.560 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-258.674 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-260.620 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-236.629 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-241.673 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-235.330 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-240.564 total time=   1.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-242.070 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-229.659 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-234.826 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-228.685 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-233.664 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-235.152 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-226.625 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-231.554 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-225.976 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-230.672 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-231.659 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-225.410 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-230.707 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-224.490 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-229.840 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-230.326 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-223.057 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-227.961 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-222.396 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-227.277 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-227.754 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-223.413 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-227.321 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-221.953 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-226.491 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-227.524 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-222.719 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-225.510 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-220.470 total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-224.570 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-225.922 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-226.704 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-231.558 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-225.717 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-230.964 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-232.051 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-224.505 total time=   1.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-228.921 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-223.493 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-228.511 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-228.857 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-224.183 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-229.056 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-222.765 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-227.535 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-227.794 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-222.677 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-227.296 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-221.718 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-226.287 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-226.508 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-222.860 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-227.072 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-222.088 total time=   1.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-226.003 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-227.430 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-222.837 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-227.497 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-222.266 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-225.622 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-227.387 total time=   0.8s\n",
      "Best parameters for XGBoost:\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best RMSE for XGBoost: 14.961223060459547\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hyperparameter Tuning the XGBoost and Random Forest Regressors\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_reg_s = XGBRegressor()\n",
    "\n",
    "# Create a GridSearchCV instance for XGBoost\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_reg, param_grid=xgb_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the GridSearchCV on your training data\n",
    "xgb_grid_search.fit(Xreg_train_scaled, yreg_train)\n",
    "\n",
    "# Print the best parameters and the corresponding RMSE\n",
    "print(\"Best parameters for XGBoost:\")\n",
    "print(xgb_grid_search.best_params_)\n",
    "print(\"Best RMSE for XGBoost:\", (-xgb_grid_search.best_score_) ** 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-258.212 total time=  12.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-265.168 total time=  10.4s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-258.610 total time=  11.9s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-265.278 total time=  13.6s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-264.578 total time=  11.6s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-258.159 total time=  20.2s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-265.321 total time=  22.6s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-258.369 total time=  27.8s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-265.588 total time=  23.4s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-264.729 total time=  31.7s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-257.911 total time=  11.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-265.310 total time=  12.2s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-258.513 total time=  10.5s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-265.464 total time=  11.6s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-264.382 total time=  19.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-258.316 total time=  22.8s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-265.253 total time=  22.6s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-258.512 total time=  26.5s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-265.390 total time=  25.9s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-264.742 total time=  30.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-258.178 total time=  12.9s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-265.090 total time=  14.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-258.543 total time=  16.6s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-265.884 total time=  11.7s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-264.672 total time=  11.7s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-258.056 total time=  24.3s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-264.718 total time=  25.7s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-258.547 total time=  25.4s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-265.608 total time=  25.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-264.654 total time=  24.3s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-249.299 total time=  20.7s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-255.550 total time=  14.3s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-249.465 total time=  15.4s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-255.379 total time=  14.9s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-256.619 total time=  14.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-249.400 total time=  29.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-255.122 total time=  35.2s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-249.481 total time=  34.6s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-255.411 total time=  32.5s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-256.496 total time=  35.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-249.311 total time=  16.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-255.658 total time=  16.3s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-249.683 total time=  16.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-255.612 total time=  14.5s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-256.574 total time=  17.6s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-249.339 total time=  33.3s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-255.115 total time=  37.2s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-249.411 total time=  33.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-255.670 total time=  31.0s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-256.748 total time=  35.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-249.613 total time=  18.8s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-255.267 total time=  18.9s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-249.154 total time=  14.5s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-255.308 total time=  14.6s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-256.333 total time=  15.8s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-249.416 total time=  29.1s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-255.229 total time=  28.9s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-249.526 total time=  36.6s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-255.712 total time=  37.3s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-256.529 total time=  30.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-243.293 total time=  19.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-248.825 total time=  18.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-243.418 total time=  17.5s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-249.020 total time=  18.7s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-250.242 total time=  18.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-243.356 total time=  40.7s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-249.019 total time=  43.4s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-243.329 total time=  35.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-249.210 total time=  39.8s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-250.264 total time=  42.2s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-243.354 total time=  19.1s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-248.961 total time=  19.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-243.459 total time=  21.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-249.075 total time=  18.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-250.442 total time=  24.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-243.430 total time=  38.2s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-248.828 total time=  36.6s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-243.414 total time=  31.8s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-249.138 total time=  33.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-250.055 total time=  33.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-243.352 total time=  16.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-248.959 total time=  16.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-243.408 total time=  16.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-249.182 total time=  16.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-250.138 total time=  16.9s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-243.314 total time=  32.4s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-249.013 total time=  34.8s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-243.501 total time=  33.9s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-249.312 total time=  43.9s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-250.147 total time=  39.1s\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "{'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best RMSE for Random Forest: 15.714949596680535\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Random Forest Regressor Hyperparameter Tuning\"\"\" \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [ 3,4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest regressor\n",
    "rf_reg_s = RandomForestRegressor()\n",
    "\n",
    "# Create a GridSearchCV instance for Random Forest\n",
    "rf_grid_search = GridSearchCV(estimator=rf_reg_s, param_grid=rf_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the GridSearchCV on your training data\n",
    "rf_grid_search.fit(Xreg_train_scaled, yreg_train)\n",
    "                   \n",
    "\n",
    "# Print the best parameters and the corresponding RMSE\n",
    "print(\"\\nBest parameters for Random Forest:\")\n",
    "print(rf_grid_search.best_params_)\n",
    "print(\"Best RMSE for Random Forest:\", (-rf_grid_search.best_score_) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating new regression models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.226271</td>\n",
       "      <td>16.195170</td>\n",
       "      <td>13.142729</td>\n",
       "      <td>6.466474e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.226174</td>\n",
       "      <td>16.196175</td>\n",
       "      <td>13.142202</td>\n",
       "      <td>6.465996e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.288222</td>\n",
       "      <td>15.533286</td>\n",
       "      <td>12.533719</td>\n",
       "      <td>5.489350e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.906654</td>\n",
       "      <td>5.625210</td>\n",
       "      <td>4.396187</td>\n",
       "      <td>1.576097e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.469507</td>\n",
       "      <td>13.410061</td>\n",
       "      <td>10.569553</td>\n",
       "      <td>3.675584e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor_tuned</td>\n",
       "      <td>0.276157</td>\n",
       "      <td>15.664377</td>\n",
       "      <td>12.604354</td>\n",
       "      <td>5.193887e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor_tuned</td>\n",
       "      <td>0.393571</td>\n",
       "      <td>14.337746</td>\n",
       "      <td>11.377276</td>\n",
       "      <td>4.131025e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  R2 Score       RMSE        MAE          MAPE\n",
       "0            Linear Regression  0.226271  16.195170  13.142729  6.466474e+15\n",
       "1                      RidgeCV  0.226174  16.196175  13.142202  6.465996e+15\n",
       "2                      LassoCV  0.288222  15.533286  12.533719  5.489350e+15\n",
       "3        RandomForestRegressor  0.906654   5.625210   4.396187  1.576097e+15\n",
       "4                 XGBRegressor  0.469507  13.410061  10.569553  3.675584e+15\n",
       "5  RandomForestRegressor_tuned  0.276157  15.664377  12.604354  5.193887e+15\n",
       "6           XGBRegressor_tuned  0.393571  14.337746  11.377276  4.131025e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.232768</td>\n",
       "      <td>16.048065</td>\n",
       "      <td>12.964561</td>\n",
       "      <td>6.245663e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.232843</td>\n",
       "      <td>16.047280</td>\n",
       "      <td>12.963581</td>\n",
       "      <td>6.245130e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.294826</td>\n",
       "      <td>15.385355</td>\n",
       "      <td>12.397866</td>\n",
       "      <td>5.342149e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.346139</td>\n",
       "      <td>14.815018</td>\n",
       "      <td>11.677546</td>\n",
       "      <td>4.286503e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.335447</td>\n",
       "      <td>14.935651</td>\n",
       "      <td>11.783014</td>\n",
       "      <td>4.253367e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor_tuned</td>\n",
       "      <td>0.280124</td>\n",
       "      <td>15.544910</td>\n",
       "      <td>12.479923</td>\n",
       "      <td>5.070215e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor_tuned</td>\n",
       "      <td>0.347625</td>\n",
       "      <td>14.798164</td>\n",
       "      <td>11.716315</td>\n",
       "      <td>4.300420e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  R2 Score       RMSE        MAE          MAPE\n",
       "0            Linear Regression  0.232768  16.048065  12.964561  6.245663e+15\n",
       "1                      RidgeCV  0.232843  16.047280  12.963581  6.245130e+15\n",
       "2                      LassoCV  0.294826  15.385355  12.397866  5.342149e+15\n",
       "3        RandomForestRegressor  0.346139  14.815018  11.677546  4.286503e+15\n",
       "4                 XGBRegressor  0.335447  14.935651  11.783014  4.253367e+15\n",
       "5  RandomForestRegressor_tuned  0.280124  15.544910  12.479923  5.070215e+15\n",
       "6           XGBRegressor_tuned  0.347625  14.798164  11.716315  4.300420e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate metrics for the 4 latest models and append them to the results DataFrame \n",
    "train_results_df, test_results_df = calculate_and_append_metrics('RandomForestRegressor', rf_reg, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('XGBRegressor', xgb_reg, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('RandomForestRegressor_tuned', rf_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('XGBRegressor_tuned', xgb_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "# display the results\n",
    "print(\"Train:\")\n",
    "display(train_results_df)\n",
    "print(\"-\"*70,\"\\n\")\n",
    "print(\"Test:\")\n",
    "display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best model\n",
    "\n",
    "The best performing model is the XGBRegressor_tuned, with the lowest RMSE and MAE values on the test set, as well as the highest $R^2$ score.\n",
    "Except the non-tuned XGBRegressor, all of the models did not over-fit. Never the less, all of the models have low goodness of fit.\n",
    "\n",
    "* $R^2$ quantifies the proportion of the variance in the dependent variable that is explained by the independent variables in our model. In this case we witness poor fit. \n",
    "* Root Mean Square Error (RMSE) is a metric used to measure the average magnitude of the errors between predicted and actual values in a regression or forecasting problem, with lower values indicating better model accuracy. In our model we used RMSE as the main target function.\n",
    "* MAE provides a straightforward measure of how far, on average, the model's predictions are from the actual values. It helps assess the model's ability to make accurate predictions while considering both overestimations and underestimations equally. Our MAE values turned relatively low, indicating accurate models.\n",
    "* MAPE is a metric of the accuracy of predictions in relative terms. It tells us how much, on average, the predictions deviate from the actual values as a percentage of the actual values. All of our models reached small MAPE values, indicating relatively accurate predictions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
